<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    <title>FONT TELLER</title>
    <link href="styles.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800&display=swap" rel="stylesheet">
  </head>

  <body>
    <header>
      <div class="row-header">
        <div class="col-header">
          <a class="style-logo">
            <p>FONT TELLER</p>
          </a>
          <nav class="style-nav">
            <ul>
              <li><a href="https://github.com/chrisgrizzly/font.teller/archive/master.zip">Download Zip</a></li>
              <li><a href="https://github.com/chrisgrizzly/font.teller">Project GitHub</a></li>
              <li><a href="https://mahdi-roozbahani.github.io/cse4240-summer2019.github.io/">Course Info</a></li>
            </ul>
          </nav>
        </div>
      </div>
    </header>

    <main>
      <section class="hero">
        <div class="hero-content"></div>
        <div class="poster">
          <img alt="" src="Banner_v7.png">
        </div>
      </section>

      <div class="break"></div>

      <section class="section-title">
        <p>Our Motivations</p>
      </section>

      <section class="section-intro">
        <p>
          Fonts make words more expressive,<br>
          <span class="attention">both aesthetically and logically.</span><br>
          That's why we think it's important to detect them.
        </p>
      </section>

      <div class="row">
        <div class="col col-md-one-half">
          <div class="info-box">
            <div class="punchline">Two Signs</div>
            <p>Even though we might not know what they mean, we have different feelings towards them. If we are told that these are restaurant logos (they are not*), we would intuitively think that the bottom one might be for one that serves French cuisine, while the top one is a family diner.</p>
            <p>Well, that's the power of fonts.</p>
          </div>
        </div>
        <div class="col col-md-one-half">
          <img alt="" src="signs-2.png">
        </div>
      </div>

      <div class="row">
        <div class="col">
          <div class="info-box">
            <p>OCR (optical character recognition) technology, which converts imagesinto texts, is mature. However, <span class="attention">font information is not generally preserved during the OCR process</span>, meaning users need to reformat the whole document from scratch. This is <span class="attention">inconvenient</span> and can possibly introduce <span class="attention">human errors</span> in editing.</p>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="col col-md-one-half">
          <div class="info-box">
              <div class="punchline">Scenario 1</div>
              <p>Converting scanned documents into digital formats</p>
              <img alt="" src="match-scanned.png">
          </div>
        </div>
        <div class="col col-md-one-half">
          <div class="info-box">
            <div class="punchline">Scenario 2</div>
            <p>Match sketched designs with standard fonts</p>
            <img alt="" src="match-handwritten.png">
          </div>
        </div>
      </div>

      <div class="row">
        <div class="col">
          <div class="info-box">
            <p>An existing app WhatTheFont uses deep learning algorithms to recognize 100,000 fonts. However, for hand-drawn characters, the app returns similar handwritten fonts (thanks to its large collection) instead of similar standard publication fonts that are ready for production. In this sense, the large collection actually hinders peopleâ€™s ability to fast-prototype using pen and paper.</p>
            <p>That's why we want to see if we can use <span class="attention">simpler models, more cost effectively, to recognize limited but major fonts.</span></p>
          </div>
        </div>
      </div>

      <div class="break"></div>

      <section class="section-title">
        <p>Our Approaches + Results</p>
      </section>

      <section class="section-intro">
        <p>
          With synthetic data, we use machine learning methods, including
          <span class="attention">random forest</span>,
          <span class="attention">logistic regression</span>,
          and <span class="attention">convolutional neural network (CNN)</span>,
          to distinguish 13 fonts. Model parameters are optimized, so are the data pre-processed with
          <span class="attention">principal component analysis (PCA).</span>
        </p>
      </section>

      <div class="break"></div>

      <!--------------------- Synthetic Data --------------------->

      <div class="row">
        <div class="col col-md-one-half">
            <div class="info-box">
              <div class="punchline">Synthetic Data</div>
              <p>We synthesized images (32-by-32 pixels) of letters in 13 fonts. To mimic the real-life data, we applied 4 maniputations to each image: <span class="attention">rotation, stretching, offset and noise.</span></p>
              <p>This process enables us to generate as many data as we need for the training purposes, with a high flexibilty.</p>
              <p>This ensures that the model can be well-trained and reduces the change of overfitting. </p>
            </div>
        </div>
        <div class="col col-md-one-half">
            <img alt="" src="Synthetic data.png">
        </div>
      </div>

      <div class="img-fw">
        <div class="centered">
          We used 13,000 images, <br>
          1,000 each font, but there really is no limit.
        </div>
        <img alt="" src="datapic.png">
      </div>

      <!--------------------- Random Forest --------------------->

      <div class="row">
          <div class="col">
            <div class="info-box">
              <div class="punchline">Random Forest</div>
              <p>Random forest is an ensembled learning model using multiple decision trees. Each tree uses a randomly picked dataset by bootstrap method, and only considers a limited features that are randomly selected.</p>
              <p>Thus, these parameters of the model are particularly of interest: <span class="attention">depth of trees</span>, <span class="attention">number of trees</span>, and <span class="attention">number of features considered each time.</span> We optimized these data using 10-fold cross validation, as well as repeated random sub-sampling.</p>
              <p>(Note that to reduce the complexity for random forest, we only used letter "H" as a proof of concept, assuming the font recognition is based on pre-defined letter images (post OCR).)</p>
            </div>
        </div>
      </div>

      <div class="row">
          <div class="col">
            <div class="info-box">
              <div class="punchline">Using the Default <i>sklearn RandomForestClassifier()</i></div>
              <p>Before optimization, after repeated 100 times random sub-sampling (training : testing = 9 : 1), the default random forest model gives <span class="attention">an average accuracy of 65%.</span></p>
              <p>(Slightly) better than random guessing. :P</p>
            </div>
        </div>
      </div>

      <div class="row">
        <div class="col col-md-one-half">
          <div class="info-box">
            <div class="punchline">Optimization of <br> the Depth of Trees</div>
                <p>On the right shows the accuracy results with various depths of trees. Both random sub-sampling and 10-fold cross validation suggests that the <span class="attention"> optimal range for depth of trees is from 9 to 14.</span></p>
                <p>Starting from depth of trees = 1, the accuracies for both training and testing data goes up as more depths provides more decision boundaries for finer and better classifications. <span class="attention">However, when further increase the depth of trees, the training accuracy goes to 1, suggesting overfitting. This is verified by the decease of testing accuracy.</span></p>
            </div>
          </div>
        <div class="col col-md-one-half">
          <img alt="" src="depth_of_trees.png">
        </div>
      </div>

      <div class="row">
          <div class="col col-md-one-half">
            <div class="info-box">
              <div class="punchline">Optimization of <br> the Number of Trees</div>
                  <p>Using the method described above, it's found that within the tested range, <span class="attention">the larger the number of trees, the better the accuracy (with no overfitting).</span></p>
                  <p>This is expected, as the more trees would average out the wrong classifications of each individual tree, statistically. (Basically the core idea behind ensemble learning.)</p>
                  <p>Due to the limitation of computation power, we chose <span class="attention">number of trees = 1000</span> (100 if by default).</p>
              </div>
            </div>
          <div class="col col-md-one-half">
            <img alt="" src="number_of_trees.png">
          </div>
        </div>

      <div class="row">
        <div class="col col-md-one-half">
          <div class="info-box">
            <div class="punchline">Optimization of <br> the Number of Features</div>
              <p>Using the method described above, it's found that the <span class="attention"> optimal number of features is 500.</span></p>
              <p>This is expected, as there is a trade-off between preserving the information and decorrelating the trees.</p>
            </div>
          </div>
        <div class="col col-md-one-half">
          <img alt="" src="number_of_features.png">
        </div>
      </div>

      <div class="row">
        <div class="col">
          <div class="info-box">
            <div class="punchline">Using the Optimized <i>RandomForestClassifier()</i></div>
            <p>After optimization, the average accuracy goes up from 65% to <span class="attention">83% (1.3X enhancement).</span></p>
            <p>The confusion matrix is shown below. An interesting finding is that by looking at large cross terms in the confusion matrix, <span class="attention">one can also infer the similarity between fonts.</span></p>
          </div>
        </div>
      </div>

      <div class="row">
          <div class="col col-md-one-half">
              <img alt="" src="Confusion-matrix-optimized-RF.png">
            </div>
        <div class="col col-md-one-half">
          <img alt="" src="similar-fonts.png">
        </div>
      </div>
      <!--------------------- PCA --------------------->

      <div class="dark-break"></div>

      <div class="row">
        <div class="col">
          <div class="info-box">
            <div class="punchline">Principal Component Analysis (PCA)</div>
            <p>PCA selects major components that maximize the variantions among data. In terms of classification problems, such as the random forest font detection we are doing here, PCA can help maximize the seperation between classes, thus <span class="attention">improve the accuracy.</span></p>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="col col-md-one-half">
          <div class="info-box">
            <div class="punchline">Optimization of the Number of Components in PCA</div>
              <p>One important parameter is <span class="attention">how many components</span> should we pass from PCA to random forest.</p>
              <p>It's found that <span class="attention">the best number of components is 25.</span> This makes sense as we can see from the reconstructed images. As the number of components increase, important font information starts to appear. Later, further increasing the number of components would also pick up the noises, which dilutes the font information. At number of components = 25, the font is distinguishble and the image is clean.</p>
            </div>
          </div>
        <div class="col col-md-one-half">
          <img alt="" src="PCA.png">
        </div>
      </div>

      <div class="row">
        <div class="col col-md-one-half">
          <div class="info-box">
            <div class="punchline">PCA + Random Forest</div>
            <p>When using PCA to pre-process the data and only selecting 25 components, optimized random forest still yeilds <span class="attention">83% accuracy</span>, even we are using far less features.</p>
            <p>This <span class="attention">reduces the computation burden</span> without sacrificing the accuracy.</p>
          </div>
        </div>
        <div class="col col-md-one-half">
          <img alt="" src="PCA-and-RF.png">
        </div>
      </div>

      <!--------------------- Comparison --------------------->

      <div class="dark-break"></div>

      <div class="row">
          <div class="col col-md-one-half">
            <div class="info-box">
              <div class="punchline">Comparison Between Models</div>
                <p>We also tested <span class="attention">logisitic regression</span>. However, the accuracy is only 63%.</p>
                <p>The differences between models are also shown in the <span class="attention">receiver operating characteristic (ROC) curve</span>. Note that since this is a multiclass problem, one-vs-all approach is used. The area under curve (AUC) is the average value for one model.</p>
                <p>As we can see, optimized random forest has the best AUC, closely followed by optimized random forest with PCA. Logistic regression and default random forest have lower AUC.</p>
              </div>
            </div>
          <div class="col col-md-one-half">
            <img alt="" src="ROC.png">
          </div>
        </div>

      <!--------------------- CNN --------------------->
      
      <div class="dark-break"></div>
    
      <div class="row">
          <div class="col">
            <div class="info-box">
              <div class="punchline">Convolutional Neural Network (CNN)</div>
              <p>We extended our project to test using home-made convolutional neural network (CNN)</p>
              <p>For CNN based deep-learning method, we generated a comprehensive dataset. The dataset consists of 13,000 font images of <span class="attention">letters a-z, A-Z and 0-9 in 13 different font families</span>. The image samples have varying levels of random noise. </p>
              <p>The deep learning model is implemented in <i>keras</i> and its architecure is shown below.  It mainly consists of two convolutional layers and one hidden layer. To reduce the complexity, <span class="attention">max pooling</span> is used with pool size of 2 and stride of 2. This halves the matrix dimensions from 28x28x64 to 14x14x64. To avoid overfitting, <span class="attention">dropout technique</span> is used in two stages with quarter and half of neurons dropped in each. In the output layer, <span class="attention">Binary Softmax classifier</span> is used to classify an input as one of the 13 font families. The resultant model has 420,685 total trainable parameters, as shown below.</p>
            </div>
        </div>
      </div>

      <div class="row">
        <div class="col col-md-one-half">
          <img alt="" src="CNN_arch.png">
        </div>
        <div class="col col-md-one-half">
          <img alt="" src="CNN_parameters.PNG">
        </div>
      </div>

      <div class="row">
        <div class="col col-md-one-half">
          <div class="info-box">
              <div class="punchline">CNN Results</div>
              <p>The above model is run for 10 epochs. The test accuracy is improved with each epoch iteration and <span class="attention">reached the max 100% in 4 epochs</span>. Train accuracy however is not no high, but it is lesser of concern than the test performance. The loss function below shows similar trend.</p>
          </div>
        </div>
        <div class="col col-md-one-half">
            <img alt="" src="CNN_accuracy.png">
          </div>
      </div>

      <div class="row">
        <div class="col col-md-one-half">
          <div class="info-box">
            <div class="punchline">Effect of<br>Numer of Neurons</div>
            <p>Number of neurons in the hidden layer is a critical parameter for the model performance and complexity. To choose it judiciously, the neuron quantity is swept from 1 to 64 as shown below. From the plot, we can observe that the <span class="attention">32-neuron layer-based model</span> offers the optimal solution for this problem. </p>
          </div>
        </div>
        <div class="col col-md-one-half">
          <img alt="" src="Neorons_compare2F.png">
        </div>
      </div>
      
      <div class="break"></div>

      <div class="break"></div>

      <section class="section-title">
        <p>Conclusions</p>
      </section>

      <section class="section-intro">
        <p>(0. Machine learning is fun.)</p>
        <p>1. Both random forest and CNN have shown promising results in font recognition, with high accuracies 83% and 100%, respectively.</p>
        <p>2. Parameter optimization and PCA can enhance the performance of random forest very much.</p>
        <p>3. (Bonus) Confusion matrix can actually tell which fonts are more similar.</p>
      </section>

      <div class="break"></div>

      <section class="section-title">
        <p>Next Steps</p>
      </section>      

      <section class="section-intro">
        <p>
          We hope this project,
          <span class="attention">achieved with simple models and low computation resources</span>,
          can inspire people (including us) to further develop font detection to benifit industries and global communities.
        </p>
        <p>Some extensions for future considerations:</p>
        <p>1. Test with real-life data, even live data from video cameras.</p>
        <p>2. Build plug-ins for applications such as PDF readers.</p>
        <p>3. Adding detections of other aspects of fonts, such as color, size, highlight, bold, italic, and underscore.</p>
        <p>...</p>
      </section>

      <div class="break"></div>

      <div class="rol">
        <div class="col">
          <div class="footer-info-box">
            <div class="punchline">Presented by Venkatesh and Zhijian (Chris) @ Georgia Tech</div>
            <p>We are students at Georgia Tech. This website is about our project in course CX 4240, Summer 2019.</p>
            <p>Website designed by Zhijian (Chris) Hao.</p>
            <p>*BTW, the two signs are written in Xhosa and mean "Thank you very much!"</p>
          </div>
        </div>
      </div>
    </main>
  </body>
</html>
